{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform imports and load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import spacy\n",
    "import re # For regular expressions|||\n",
    "import string # For handling string\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "import vaderSentiment\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.util import ngrams\n",
    "#import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from collections import  Counter\n",
    "#import gensim\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "#from textblob import TextBlob\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading data\n",
    "df = pd.read_csv(r'C:/Users/NB332021/OneDrive - Nedbank/Desktop/Thesis/Data/Model Data/LabData.csv')\n",
    "df2 = pd.read_excel(r'C:/Users/NB332021/OneDrive - Nedbank/Desktop/Thesis/Data/Model Data/TrainingSet.xlsx')\n",
    "df1 = df[0:10000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate only labeled data\n",
    "df1 = df1.dropna(subset=\"label\").reset_index()\n",
    "df1[\"label\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING DATA\n",
    "#drop duplicates\n",
    "df1 = df1.drop_duplicates(keep='first')\n",
    "#removing numbers\n",
    "df1['text'] = df1['text'].astype('string')\n",
    "df1.dropna(subset=['text'], inplace=True)\n",
    "#lowercase\n",
    "df1['text']=df1['text'].apply(lambda x: x.lower())\n",
    "#removing mentions\n",
    "df1['text']=df1['text'].apply(lambda x: re.sub(\"@[A-Za-z0-9_]+\",'', x))\n",
    "#removing numbers and words containing numbers\n",
    "df1['text']=df1['text'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "#removing hashtags?\n",
    "#df1['text']=df1['text'].apply(lambda x: re.sub(\"#[A-Za-z0-9_]+\",'', x))\n",
    "#df1['text']=df1['text'].apply(lambda x: re.split('#|_', x))\n",
    "df1['text']=df1['text'].apply(lambda x: \" \".join(word.strip() for word in re.split('#|_', x)))\n",
    "#removing links\n",
    "df1['text']=df1['text'].apply(lambda x: re.sub(r\"http\\S+\",'', x))\n",
    "df1['text']=df1['text'].apply(lambda x: re.sub(r\"www.\\S+\",'', x))\n",
    "#removing punctuation\n",
    "df1['text']=df1['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "#removing empty spaces and special characters\n",
    "df1['text']=df1['text'].apply(lambda x: re.sub('[^A-Za-z0-9]+',' ',x))\n",
    "#stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Print the set of spaCy's default stop words (remember that sets are unordered):\n",
    "print(nlp.Defaults.stop_words)\n",
    "#add twitter as a stop word and rt\n",
    "# Add the word to the set of stop words. Use LOWERCASE!\n",
    "nlp.Defaults.stop_words.add('twitter')\n",
    "nlp.Defaults.stop_words.add('rt')\n",
    "nlp.Defaults.stop_words.add('s')\n",
    "nlp.Defaults.stop_words.add('tweet')\n",
    "nlp.Defaults.stop_words.add('trend')\n",
    "nlp.Defaults.stop_words.add('follower')\n",
    "nlp.Defaults.stop_words.add('null')\n",
    "nlp.Defaults.stop_words.add('http')\n",
    "nlp.Defaults.stop_words.add('url')\n",
    "nlp.Defaults.stop_words.add('trend')\n",
    "nlp.Defaults.stop_words.add('trending')\n",
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['twitter'].is_stop = True\n",
    "nlp.vocab['rt'].is_stop = True\n",
    "nlp.vocab['s'].is_stop = True\n",
    "nlp.vocab['tweet'].is_stop = True\n",
    "nlp.vocab['trend'].is_stop = True\n",
    "nlp.vocab['follower'].is_stop = True\n",
    "nlp.vocab['null'].is_stop = True\n",
    "nlp.vocab['http'].is_stop = True\n",
    "nlp.vocab['url'].is_stop = True\n",
    "nlp.vocab['trend'].is_stop = True\n",
    "nlp.vocab['trending'].is_stop = True\n",
    "stop = nlp.Defaults.stop_words\n",
    "#lemmatisation\n",
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    " \n",
    "# Lemmatization with stopwords removal\n",
    "#df1[\"text\"]=df1[\"text\"].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if ((token.is_stop==False)&((token.pos_==\"ADJ\")|(token.pos_==\"NOUN\")|(token.pos_==\"VERB\")))]))\n",
    "#df1.head()\n",
    " \n",
    "df1[\"text\"]=df1[\"text\"].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if ((token.is_stop==False))]))\n",
    " \n",
    "#getting rid of empty text rows\n",
    "df1.dropna(subset = \"text\", inplace=True)\n",
    "df1.shape\n",
    " \n",
    "#removing \"lab\"\n",
    "df1['label'] = df1['label'].apply(lambda x: int(0) if x == 'lab' else int(x))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#calculating document frequency\n",
    "#MI doesnt take in continuous data therefore TD-IDf wont work\n",
    "#need to use document frequency since values are discrete\n",
    "vectorizer = CountVectorizer()\n",
    "DF = vectorizer.fit_transform(df1[\"text\"])\n",
    "#Y = pd.DataFrame(data=X1)\n",
    "#DF = pd.DataFrame(data=Y, columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many features we are looking at\n",
    "#might be cutting it off too early\n",
    " \n",
    "#libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#_____________________________________________________________________________________________\n",
    "#checking the performance of the feature selection\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit and transform the training data\n",
    "X_tfidf = vectorizer.fit_transform(df1['text'])\n",
    "y = df1[\"label\"]\n",
    "upper = 4000\n",
    "jump = 500\n",
    "lower = 1\n",
    "#create a loop\n",
    "XMSE_CHI = [0] * len(range(lower,upper,jump))\n",
    "XMSE_MI = [0] * len(range(lower,upper,jump))\n",
    "XMSE_LSA = [0] * len(range(lower,upper,jump))\n",
    " \n",
    "XACC_CHI = [0] * len(range(lower,upper,jump))\n",
    "XACC_MI = [0] * len(range(lower,upper,jump))\n",
    "XACC_LSA = [0] * len(range(lower,upper,jump))\n",
    " \n",
    "#RFMSE_CHI = [0] * len(range(lower,upper,jump))\n",
    "#RFMSE_MI = [0] * len(range(lower,upper,jump))\n",
    "#RFMSE_LSA = [0] * len(range(lower,upper,jump))\n",
    " \n",
    "#RFACC_CHI = [0] * len(range(lower,upper,jump))\n",
    "#RFACC_MI = [0] * len(range(lower,upper,jump))\n",
    "#RFACC_LSA = [0] * len(range(lower,upper,jump))\n",
    " \n",
    "#SMSE_CHI = [0] * len(range(lower,upper,jump))\n",
    "#SMSE_MI = [0] * len(range(lower,upper,jump))\n",
    "#SMSE_LSA = [0] * len(range(lower,upper,jump))\n",
    " \n",
    "#SACC_CHI = [0] * len(range(lower,upper,jump))\n",
    "#SACC_MI = [0] * len(range(lower,upper,jump))\n",
    "#SACC_LSA = [0] * len(range(lower,upper,jump))\n",
    " \n",
    "for nfeatures in range(lower, upper, jump):\n",
    "    for n in range(len(range(lower,upper,jump))):\n",
    "        #need to encode labels\n",
    "        le = LabelEncoder()\n",
    "        yX = le.fit_transform(y)\n",
    "        #transformed -1 -> 0, 0 -> 1, 1 -> 2\n",
    "        #______________________________________________________________________________________________\n",
    "        #chi-square\n",
    "        #approach 1\n",
    "        chi2_features = SelectKBest(score_func=chi2,k=nfeatures)\n",
    "        ChiX_selected = chi2_features.fit_transform(X_tfidf, yX)\n",
    "        # Split the data into training and testing sets\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(ChiX_selected, yX, test_size=0.2, random_state=42)\n",
    "       \n",
    "        #approach 2\n",
    "        #information gain\n",
    "        mi_features = SelectKBest(score_func=mutual_info_classif, k=nfeatures)\n",
    "        miX_selected = mi_features.fit_transform(DF, yX)\n",
    "        # Split the data into training and testing sets\n",
    "        X_train2, X_test2, y_train2, y_test2 = train_test_split(miX_selected, yX, test_size=0.2, random_state=42)\n",
    " \n",
    "        #LSA - PCA (matrix too sparse - LSA similiar to PCA but more suitable for parse matrices\n",
    "        #perform LSA\n",
    "        svd = TruncatedSVD(n_components=nfeatures)\n",
    "        X_svd = svd.fit_transform(X_tfidf)\n",
    "        # Split the data into training and testing sets\n",
    "        X_train3, X_test3, y_train3, y_test3 = train_test_split(X_svd, yX, test_size=0.2, random_state=42)\n",
    " \n",
    "        #test the performance of the three feature selection techniques\n",
    "        #____________________________________________________________________________\n",
    "       \n",
    "        #XGBoost\n",
    "        # Fit the XGBoost model to the training data\n",
    "        XGB1 = XGBClassifier()\n",
    "        XGB2 = XGBClassifier()\n",
    "        XGB3 = XGBClassifier()\n",
    "        #using chi\n",
    "        XGB1.fit(X_train1, y_train1)\n",
    "        #using mi\n",
    "        XGB2.fit(X_train2, y_train2)\n",
    "        #using LSA\n",
    "        XGB3.fit(X_train3, y_train3)\n",
    " \n",
    "        # Predict the labels of the testing data\n",
    "        y_pred1 = XGB1.predict(X_test1)\n",
    "        y_pred2 = XGB2.predict(X_test2)\n",
    "        y_pred3 = XGB3.predict(X_test3)\n",
    " \n",
    "        # Print the accuracy of the model\n",
    "        XACC_CHI[n]=accuracy_score(y_test1, y_pred1)\n",
    "        XACC_MI[n]=accuracy_score(y_test2, y_pred2)\n",
    "        XACC_LSA[n]=accuracy_score(y_test3, y_pred3)\n",
    " \n",
    "        # Print the MSE of the model\n",
    "        XMSE_CHI[n]=mean_squared_error(y_test1, y_pred1)\n",
    "        XMSE_MI[n]=mean_squared_error(y_test2, y_pred2)\n",
    "        XMSE_LSA[n]=mean_squared_error(y_test3, y_pred3)\n",
    " \n",
    "        #random forest\n",
    "        #____________________________________________________________________________________________\n",
    "        #Random forest classifier\n",
    "        # Fit the Random Forest model to the training data\n",
    "        #RFC1 = RandomForestClassifier()\n",
    "        #RFC2 = RandomForestClassifier()\n",
    "        #RFC3 = RandomForestClassifier()\n",
    " \n",
    "        #RFC1.fit(X_train1, y_train1)\n",
    "        #RFC2.fit(X_train2, y_train2)\n",
    "        #RFC3.fit(X_train3, y_train3)\n",
    " \n",
    "        # Predict the labels of the testing data\n",
    "        #y_pred1 = RFC1.predict(X_test1)\n",
    "        #y_pred2 = RFC2.predict(X_test2)\n",
    "        #y_pred3 = RFC3.predict(X_test3)\n",
    " \n",
    "        # Print the accuracy of the model\n",
    "        #RFACC_CHI[n]=accuracy_score(y_test1, y_pred1)\n",
    "        #RFACC_MI[n]=accuracy_score(y_test2, y_pred2)\n",
    "        #RFACC_LSA[n]=accuracy_score(y_test3, y_pred3)\n",
    " \n",
    "        # Print the MSE of the model\n",
    "        #RFMSE_CHI[n]=mean_squared_error(y_test1, y_pred1)\n",
    "        #RFMSE_MI[n]=mean_squared_error(y_test2, y_pred2)\n",
    "        #RFMSE_LSA[n]=mean_squared_error(y_test3, y_pred3)\n",
    " \n",
    "        #Support vector machine\n",
    "        #___________________________________________________________________________________________\n",
    "        # Fit the Random Forest model to the training data\n",
    "        #SVC1 = OneVsRestClassifier(SVC())\n",
    "        #SVC2  = OneVsRestClassifier(SVC())\n",
    "        #SVC3  = OneVsRestClassifier(SVC())\n",
    " \n",
    "        #SVC1.fit(X_train1, y_train1)\n",
    "        #SVC2.fit(X_train2, y_train2)\n",
    "        #SVC3.fit(X_train3, y_train3)\n",
    " \n",
    "        # Predict the labels of the testing data\n",
    "        #y_pred1 = SVC1.predict(X_test1)\n",
    "        #y_pred2 = SVC2.predict(X_test2)\n",
    "        #y_pred3 = SVC3.predict(X_test3)\n",
    " \n",
    "        # Print the accuracy of the model\n",
    "        #SACC_CHI[n]=accuracy_score(y_test1, y_pred1)\n",
    "        #SACC_MI[n]=accuracy_score(y_test2, y_pred2)\n",
    "        #SACC_LSA[n]=accuracy_score(y_test3, y_pred3)\n",
    " \n",
    "        # Print the MSE of the model\n",
    "        #SMSE_CHI[n]=mean_squared_error(y_test1, y_pred1)\n",
    "        #SMSE_MI[n]=mean_squared_error(y_test2, y_pred2)\n",
    "        #SMSE_LSA[n]=mean_squared_error(y_test3, y_pred3)\n",
    " \n",
    "print(XMSE_CHI)\n",
    "print(XMSE_MI)\n",
    "print(XMSE_LSA)\n",
    " \n",
    "#print(RFMSE_CHI)\n",
    "#print(RFMSE_MI)\n",
    "#print(RFMSE_LSA)\n",
    " \n",
    "#print(SMSE_CHI)\n",
    "#print(SMSE_MI)\n",
    "#print(SMSE_LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT\n",
    "#create list\n",
    "nfeatures = list(range(1,4000,500))\n",
    "print(nfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the comparison of the chi-sqaure feature selection across models\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(nfeatures, XMSE_CHI)\n",
    "plt.plot(nfeatures, SMSE_CHI)\n",
    "plt.plot(nfeatures, RFMSE_CHI)\n",
    "plt.title(\"Comparison Chi-square performance across models\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend([\"XGBoost\", \"SVC\", \"Random Forest\"])\n",
    "plt.show\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the comparison of the IG feature selection across models\n",
    "plt.plot(nfeatures, XMSE_MI)\n",
    "plt.plot(nfeatures, SMSE_MI)\n",
    "plt.plot(nfeatures, RFMSE_MI)\n",
    "plt.title(\"Comparison IG performance across models\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend([\"XGBoost\", \"SVC\", \"Random Forest\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the comparison of the LSA feature selection across models\n",
    "plt.plot(nfeatures, XMSE_LSA)\n",
    "plt.plot(nfeatures, SMSE_LSA)\n",
    "plt.plot(nfeatures, RFMSE_LSA)\n",
    "plt.title(\"Comparison LSA performance across models\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend([\"XGBoost\", \"SVC\", \"Random Forest\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all FS techniques performance tested on XGBoost (MSE)\n",
    "plt.plot(nfeatures, XMSE_CHI)\n",
    "plt.plot(nfeatures, XMSE_MI)\n",
    "plt.plot(nfeatures, XMSE_LSA)\n",
    "plt.title(\"Comparison of all FS techniques, performance tested by XGBoost\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend([\"Chi-square\", \"Mutual information\", \"LSA\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all FS techniques performance tested on XGBoost (Accuracy)\n",
    "plt.plot(nfeatures, XACC_CHI)\n",
    "plt.plot(nfeatures, XACC_MI)\n",
    "plt.plot(nfeatures, XACC_LSA)\n",
    "plt.title(\"Comparison of all FS techniques, performance tested by XGBoost\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Chi-square\", \"Mutual information\", \"LSA\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all FS techniques performance tested on Random Forest (MSE)\n",
    "plt.plot(nfeatures, RFMSE_CHI)\n",
    "plt.plot(nfeatures, RFMSE_MI)\n",
    "plt.plot(nfeatures, RFMSE_LSA)\n",
    "plt.title(\"Comparison of all FS techniques, performance tested by Random Forest\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend([\"Chi-square\", \"Mutual information\", \"LSA\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all FS techniques performance tested on Random Forest (Accuracy)\n",
    "plt.plot(nfeatures, RFACC_CHI)\n",
    "plt.plot(nfeatures, RFACC_MI)\n",
    "plt.plot(nfeatures, RFACC_LSA)\n",
    "plt.title(\"Comparison of all FS techniques, performance tested by Random Forest\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Chi-square\", \"Mutual information\", \"LSA\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all FS techniques performance tested on SVM (MSE)\n",
    "plt.plot(nfeatures, SMSE_CHI)\n",
    "plt.plot(nfeatures, SMSE_MI)\n",
    "plt.plot(nfeatures, SMSE_LSA)\n",
    "plt.title(\"Comparison of all FS techniques, performance tested by SVC\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend([\"Chi-square\", \"Mutual information\", \"LSA\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All FS techniques performance tested on SVM (Accuracy)\n",
    "plt.plot(nfeatures, SACC_CHI)\n",
    "plt.plot(nfeatures, SACC_MI)\n",
    "plt.plot(nfeatures, SACC_LSA)\n",
    "plt.title(\"Comparison of all FS techniques, performance tested by SVC\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Chi-square\", \"Mutual information\", \"LSA\"])\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
